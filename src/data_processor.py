# -*- coding: utf-8 -*-
"""data_processor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eGl3keFLlYPygFu1HyBJ2CXhjQM_IBq_

data_processor.py - 資料處理
"""

import pandas as pd
import numpy as np
import logging
from pathlib import Path
from typing import Union, Tuple, Dict

logger = logging.getLogger(__name__)

class DataProcessor:
    """
    負責讀取、驗證、清理製造業資料。
    """

    SUPPORTED_FORMATS = {'.csv', '.xlsx', '.json'}
    NUMERIC_COLS_PATTERNS = ['temp', 'pressure', 'time', 'rate', 'yield', 'cpk', 'value']

    def __init__(self, max_rows: int = 50000):
        self.max_rows = max_rows
        self.df = None
        self.metadata = {}

    def load_file(self, file_obj: Union[str, Path, "UploadedFile"]) -> pd.DataFrame:

        """讀取CSV/Excel/JSON  既可以吃檔案路徑 (str/Path)，也可以吃 Streamlit UploadedFile"""

        try:
            # 1) 如果是 Streamlit UploadedFile 物件（有 name 和 read）
            if hasattr(file_obj, "name") and hasattr(file_obj, "read"):
                suffix = Path(file_obj.name).suffix.lower()
                if suffix == ".csv":
                    df = pd.read_csv(file_obj)
                elif suffix == ".xlsx":
                    df = pd.read_excel(file_obj)
                elif suffix == ".json":
                    df = pd.read_json(file_obj)
                else:
                    raise ValueError(f"Unsupported format: {suffix}")
            else:
                # 2) 原本走檔案路徑的邏輯
                file_path = Path(file_obj)
                suffix = file_path.suffix.lower()
                if suffix == ".csv":
                    df = pd.read_csv(file_path, nrows=self.max_rows)
                elif suffix == ".xlsx":
                    df = pd.read_excel(file_path, nrows=self.max_rows)
                elif suffix == ".json":
                    df = pd.read_json(file_path)
                else:
                    raise ValueError(f"Unsupported format: {suffix}")

            self.df = df
            self._extract_metadata()
            return df

        except Exception as e:
            logger.error(f"Error loading file: {e}")
            raise

    def _extract_metadata(self):
        """自動提取資料特徵"""
        if self.df is None:
            return

        self.metadata = {
            'shape': self.df.shape,
            'columns': list(self.df.columns),
            'dtypes': self.df.dtypes.to_dict(),
            'numeric_cols': self.df.select_dtypes(include=[np.number]).columns.tolist(),
            'missing_pct': (self.df.isnull().sum() / len(self.df) * 100).to_dict(),
            'basic_stats': self.df.describe().to_dict(),
        }

    def clean_data(self,
                   fill_strategy: str = 'forward',  # 'forward', 'backward', 'drop', 'mean'
                   outlier_method: str = 'iqr') -> pd.DataFrame:  # 'iqr' or 'zscore'
        """清理缺失值與異常值"""
        if self.df is None:
            raise ValueError("No data loaded. Call load_file() first.")

        df = self.df.copy()

        # 處理缺失值
        if fill_strategy == 'forward':
            df = df.fillna(method='ffill').fillna(method='bfill')
        elif fill_strategy == 'backward':
            df = df.fillna(method='bfill').fillna(method='ffill')
        elif fill_strategy == 'mean':
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
        elif fill_strategy == 'drop':
            df = df.dropna()

        # 處理異常值 (數值列)
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if outlier_method == 'iqr':
            for col in numeric_cols:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower = Q1 - 1.5 * IQR
                upper = Q3 + 1.5 * IQR
                df = df[(df[col] >= lower) & (df[col] <= upper)]

        logger.info(f"Data cleaned: {len(df)} rows remaining (removed {len(self.df) - len(df)})")
        self.df = df
        return df

    def get_summary(self) -> str:
        """生成資料摘要供prompt使用"""
        if self.df is None:
            return ""

        summary = f"""
Dataset Summary:
- Shape: {self.df.shape}
- Columns: {', '.join(self.df.columns)}
- Numeric columns: {', '.join(self.metadata.get('numeric_cols', []))}
- Missing data: {self.metadata.get('missing_pct', {})}
- Sample rows (first 3):
{self.df.head(3).to_string()}
"""
        return summary